# bot_worker.py - Vers√£o com Extra√ß√£o Din√¢mica de Dependentes
import logging
import time
import random
import httpx
import re
from bs4 import BeautifulSoup
from typing import List, Dict, Optional
from config import (BASE_URL, JOGO_SLUG, TARGET_SECTOR_SLUG,
                    MAX_WATCH_ATTEMPTS, WATCH_INTERVAL_MIN, WATCH_INTERVAL_MAX,
                    HEADERS, DEBUG_HTML_FILE, SETORES_URL, CATEGORIA_URL)
from session_manager import get_authenticated_session

# Configura√ß√£o do logging para este processo
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
    handlers=[logging.FileHandler("log_reserva_final.txt", encoding="utf-8"),
              logging.StreamHandler()],
)
log = logging.getLogger("bot-worker")

def extract_dependentes_from_page(soup: BeautifulSoup) -> List[Dict[str, str]]:
    """
    Extrai todos os dependentes dispon√≠veis da p√°gina do setor.
    Retorna lista de dicion√°rios com informa√ß√µes dos dependentes.
    """
    dependentes = []
    
    # Procura por inputs com name="dependentes"
    dependente_inputs = soup.find_all("input", {"name": "dependentes", "type": "checkbox"})
    
    if not dependente_inputs:
        log.warning("‚ö†Ô∏è Nenhum input de dependente encontrado na p√°gina")
        return dependentes
    
    log.info(f"üîç Encontrados {len(dependente_inputs)} dependentes dispon√≠veis:")
    
    for input_elem in dependente_inputs:
        dependente_id = input_elem.get('value', '')
        dependente_html_id = input_elem.get('id', '')
        
        # Tenta extrair o nome do dependente do label associado
        dependente_name = "Desconhecido"
        
        # Procura pelo label associado
        if dependente_html_id:
            label = soup.find("label", {"for": dependente_html_id})
            if label:
                # Remove texto do input e pega s√≥ o nome
                name_text = label.get_text(strip=True)
                # Remove quebras de linha e espa√ßos extras
                dependente_name = re.sub(r'\s+', ' ', name_text).strip()
        
        dependente_info = {
            'id': dependente_id,
            'name': dependente_name,
            'html_id': dependente_html_id
        }
        
        dependentes.append(dependente_info)
        log.info(f"  üë§ ID: {dependente_id} | Nome: {dependente_name}")
    
    return dependentes

def select_best_dependente(dependentes: List[Dict[str, str]]) -> Optional[Dict[str, str]]:
    """
    Seleciona o melhor dependente para usar na reserva.
    Por enquanto, usa o primeiro dispon√≠vel, mas pode ser expandido com l√≥gica mais complexa.
    """
    if not dependentes:
        log.error("‚ùå Nenhum dependente dispon√≠vel para sele√ß√£o")
        return None
    
    # Por enquanto, usa o primeiro dependente dispon√≠vel
    selected = dependentes[0]
    log.info(f"üéØ Dependente selecionado: {selected['name']} (ID: {selected['id']})")
    
    return selected

def detect_sectors_page_type(soup: BeautifulSoup) -> str:
    """
    Detecta o tipo de p√°gina de setores.
    Retorna: 'svg_map', 'link_list', ou 'unknown'
    """
    # Verifica se existe mapa SVG com setores
    svg_sectors = soup.find_all(class_="sector")
    if svg_sectors:
        log.info("  üìä Tipo de p√°gina detectado: MAPA SVG")
        return "svg_map"
    
    # Verifica se existe lista de links para setores
    sector_links = soup.find_all("a", href=re.compile(r"/setor/[^/]+/modo-de-compra/"))
    if sector_links:
        log.info("  üìä Tipo de p√°gina detectado: LISTA DE LINKS")
        return "link_list"
    
    log.warning("  ‚ö†Ô∏è Tipo de p√°gina DESCONHECIDO - nenhum formato reconhecido")
    return "unknown"

def analyze_svg_sectors(soup: BeautifulSoup) -> bool:
    """
    Analisa setores no formato de mapa SVG (formato original).
    Retorna True se o setor alvo estiver dispon√≠vel.
    """
    all_sector_elements = soup.find_all(class_="sector")
    
    if not all_sector_elements:
        log.warning("‚ö†Ô∏è Nenhum setor SVG encontrado!")
        return False
    
    log.info("  üìä [AN√ÅLISE DOS SETORES - MAPA SVG]")
    
    target_found_and_available = False
    available_sectors = []
    unavailable_count = 0
    
    # Analisa todos os setores de forma eficiente
    for sector_element in all_sector_elements:
        sector_slug = sector_element.get('id', 'desconhecido')
        is_disabled = 'disabled' in sector_element.get('class', [])
        
        if sector_slug == TARGET_SECTOR_SLUG:
            # Setor alvo - sempre mostra com destaque
            if not is_disabled:
                log.info(f"  üéØ Setor '{sector_slug.upper()}': ‚úÖ DISPON√çVEL <--- ALVO ENCONTRADO!")
                target_found_and_available = True
            else:
                log.info(f"  üéØ Setor '{sector_slug.upper()}': ‚ùå Indispon√≠vel <--- ALVO")
        elif not is_disabled:
            # Outros setores dispon√≠veis
            available_sectors.append(sector_slug)
        else:
            unavailable_count += 1
    
    # Mostra resumo dos outros setores
    if available_sectors:
        show_sectors = available_sectors[:5]
        log.info(f"  ‚úÖ Outros setores dispon√≠veis: {', '.join(show_sectors).upper()}")
        if len(available_sectors) > 5:
            log.info(f"  ‚ûï ... e mais {len(available_sectors) - 5} setores dispon√≠veis")
    
    if unavailable_count > 0:
        log.info(f"  ‚ùå Setores indispon√≠veis: {unavailable_count}")
    
    log.info(f"  üìà Total analisado: {len(all_sector_elements)} setores")
    
    return target_found_and_available

def analyze_link_sectors(soup: BeautifulSoup) -> bool:
    """
    Analisa setores no formato de lista de links.
    Retorna True se o setor alvo estiver dispon√≠vel.
    """
    # Procura por links que seguem o padr√£o /setor/NOME-SETOR/modo-de-compra/
    sector_links = soup.find_all("a", href=re.compile(r"/setor/[^/]+/modo-de-compra/"))
    
    if not sector_links:
        log.warning("‚ö†Ô∏è Nenhum link de setor encontrado!")
        return False
    
    log.info("  üìä [AN√ÅLISE DOS SETORES - LISTA DE LINKS]")
    
    target_found_and_available = False
    available_sectors = []
    
    # Analisa todos os links de setores
    for link in sector_links:
        href = link.get('href', '')
        
        # Extrai o slug do setor do link
        # Exemplo: /jogos/corinthians-x-sao-jose-cpb25/setor/cadeira-vip/modo-de-compra/
        # Padr√£o: /setor/([^/]+)/modo-de-compra/
        match = re.search(r"/setor/([^/]+)/modo-de-compra/", href)
        if not match:
            continue
            
        sector_slug = match.group(1)
        
        # Tenta extrair o nome do setor do texto do link
        sector_text = link.get_text(strip=True) if link.get_text(strip=True) else sector_slug.upper()
        
        if sector_slug == TARGET_SECTOR_SLUG:
            # Setor alvo encontrado - se existe o link, est√° dispon√≠vel
            log.info(f"  üéØ Setor '{sector_slug.upper()}' ({sector_text}): ‚úÖ DISPON√çVEL <--- ALVO ENCONTRADO!")
            target_found_and_available = True
        else:
            # Outros setores dispon√≠veis
            available_sectors.append(f"{sector_slug} ({sector_text})")
    
    # Mostra resumo dos outros setores
    if available_sectors:
        show_sectors = available_sectors[:3]  # Reduzido para 3 porque os nomes s√£o maiores
        log.info(f"  ‚úÖ Outros setores dispon√≠veis: {', '.join(show_sectors)}")
        if len(available_sectors) > 3:
            log.info(f"  ‚ûï ... e mais {len(available_sectors) - 3} setores dispon√≠veis")
    
    log.info(f"  üìà Total analisado: {len(sector_links)} setores")
    
    return target_found_and_available

def analyze_and_log_sectors(soup: BeautifulSoup) -> bool:
    """
    Analisa setores de forma inteligente, detectando o tipo de p√°gina.
    Retorna True se o setor alvo estiver dispon√≠vel.
    """
    # Detecta o tipo de p√°gina
    page_type = detect_sectors_page_type(soup)
    
    if page_type == "svg_map":
        return analyze_svg_sectors(soup)
    elif page_type == "link_list":
        return analyze_link_sectors(soup)
    else:
        log.error("‚ùå Tipo de p√°gina n√£o reconhecido - imposs√≠vel analisar setores")
        
        # Debug: salva conte√∫do para an√°lise
        debug_content = soup.get_text()[:500]
        log.info(f"  üîç Debug - Primeiros 500 chars: {debug_content}")
        
        # Verifica se tem algum indicador de setores
        if "setor" in debug_content.lower():
            log.info("  üí° A palavra 'setor' foi encontrada, mas formato n√£o reconhecido")
        
        return False

def get_target_sector_url() -> str:
    """
    Constr√≥i a URL do setor alvo baseada no formato atual.
    Mant√©m compatibilidade com ambos os formatos.
    """
    # URL padr√£o (formato antigo)
    standard_url = f"{BASE_URL}/jogos/{JOGO_SLUG}/setor/{TARGET_SECTOR_SLUG}/"
    
    # URL com modo-de-compra (formato novo)
    new_format_url = f"{BASE_URL}/jogos/{JOGO_SLUG}/setor/{TARGET_SECTOR_SLUG}/modo-de-compra/"
    
    # Por padr√£o, retorna o formato padr√£o
    # A l√≥gica do ataque tentar√° ambos se necess√°rio
    return standard_url

def attempt_sector_attack(client: httpx.Client, soup: BeautifulSoup) -> bool:
    """
    Tenta atacar o setor alvo com estrat√©gias m√∫ltiplas e extra√ß√£o din√¢mica de dependentes.
    """
    log.info("‚ö° Iniciando sequ√™ncia de ataque...")
    
    # Estrat√©gia 1: URL padr√£o (formato SVG)
    standard_url = f"{BASE_URL}/jogos/{JOGO_SLUG}/setor/{TARGET_SECTOR_SLUG}/"
    
    # Estrat√©gia 2: URL com modo-de-compra (formato lista)
    modo_compra_url = f"{BASE_URL}/jogos/{JOGO_SLUG}/setor/{TARGET_SECTOR_SLUG}/modo-de-compra/"
    
    # Estrat√©gia 3: Procurar o link exato na p√°gina atual (para formato lista)
    direct_link = None
    sector_links = soup.find_all("a", href=re.compile(rf"/setor/{re.escape(TARGET_SECTOR_SLUG)}/modo-de-compra/"))
    if sector_links:
        direct_link = BASE_URL + sector_links[0].get('href')
        log.info(f"  üîó Link direto encontrado: {direct_link}")
    
    # Lista de URLs para tentar em ordem de prioridade
    urls_to_try = []
    
    if direct_link:
        urls_to_try.append(("Link Direto", direct_link))
    
    urls_to_try.extend([
        ("Padr√£o", standard_url),
        ("Modo Compra", modo_compra_url)
    ])
    
    for strategy_name, target_url in urls_to_try:
        try:
            log.info(f"  üéØ Tentativa {strategy_name}: {target_url}")
            
            # 1. Acessa a p√°gina do setor
            client.headers['Referer'] = SETORES_URL
            sector_response = client.get(target_url)
            
            # Verifica se houve redirecionamento para login (sess√£o expirou)
            if "/auth/login/" in str(sector_response.url):
                log.error("‚ùå SESS√ÉO EXPIROU durante o ataque!")
                return False
            
            # Verifica se a resposta √© v√°lida
            if sector_response.status_code != 200:
                log.warning(f"  ‚ö†Ô∏è {strategy_name} retornou status {sector_response.status_code}")
                continue
            
            log.info(f"  ‚úÖ {strategy_name}: P√°gina acessada com sucesso")
            
            # 2. Analisa o conte√∫do da p√°gina do setor
            sector_soup = BeautifulSoup(sector_response.text, "html.parser")
            
            # Verifica se est√° realmente na p√°gina do setor correto
            if TARGET_SECTOR_SLUG.upper() not in sector_response.text.upper():
                log.warning(f"  ‚ö†Ô∏è {strategy_name}: P√°gina n√£o cont√©m refer√™ncia ao setor alvo")
                continue
            
            # 3. NOVA FUNCIONALIDADE: Extrai dependentes dinamicamente
            log.info(f"  üë• {strategy_name}: Extraindo dependentes da p√°gina...")
            dependentes = extract_dependentes_from_page(sector_soup)
            
            if not dependentes:
                log.error(f"  ‚ùå {strategy_name}: Nenhum dependente encontrado na p√°gina")
                continue
            
            # Seleciona o melhor dependente
            selected_dependente = select_best_dependente(dependentes)
            if not selected_dependente:
                log.error(f"  ‚ùå {strategy_name}: Falha na sele√ß√£o de dependente")
                continue
            
            # 4. Extrai CSRF token
            csrf_element = sector_soup.find("input", {"name": "csrfmiddlewaretoken"})
            if not csrf_element:
                log.warning(f"  ‚ö†Ô∏è {strategy_name}: CSRF token n√£o encontrado")
                continue
            
            csrf_token = csrf_element.get("value")
            log.info(f"  üîë {strategy_name}: CSRF token extra√≠do")
            
            # 5. Prepara payload para reserva com dependente selecionado
            payload = {
                "csrfmiddlewaretoken": csrf_token,
                "dependentes": selected_dependente['id']  # Usa ID extra√≠do dinamicamente
            }
            
            log.info(f"  üìã {strategy_name}: Payload preparado com dependente {selected_dependente['name']}")
            
            # 6. Executa reserva
            client.headers['Referer'] = target_url
            log.info(f"  üéØ {strategy_name}: Executando reserva...")
            
            post_response = client.post(target_url, data=payload)
            
            # 7. Verifica resultado
            if post_response.history:
                redirect_location = post_response.history[0].headers.get("location", "")
                if "/ingressos/" in redirect_location:
                    success_url = f"{BASE_URL}{redirect_location}"
                    log.info(f"üéâ SUCESSO TOTAL! RESERVA CONFIRMADA via {strategy_name}!")
                    log.info(f"üé´ URL da reserva: {success_url}")
                    log.info(f"üë§ Dependente usado: {selected_dependente['name']} (ID: {selected_dependente['id']})")
                    log.info("üèÜ MISS√ÉO CUMPRIDA! Bot conclu√≠do com √™xito.")
                    return True
                else:
                    log.warning(f"  ‚ö†Ô∏è {strategy_name}: Redirecionamento inesperado: {redirect_location}")
            
            # Verifica se est√° na p√°gina de ingressos
            if "/ingressos/" in post_response.url.path:
                log.info(f"üéâ SUCESSO! Reserva confirmada via {strategy_name}!")
                log.info(f"üé´ URL final: {post_response.url}")
                log.info(f"üë§ Dependente usado: {selected_dependente['name']} (ID: {selected_dependente['id']})")
                return True
            
            log.warning(f"  ‚ùå {strategy_name}: Tentativa falhou")
            
        except Exception as attack_error:
            log.error(f"  üí• Erro na tentativa {strategy_name}: {attack_error}")
            continue
    
    log.error("‚ùå TODAS AS ESTRAT√âGIAS DE ATAQUE FALHARAM!")
    return False

def watch_and_attack(session_cookies: dict) -> bool:
    """
    Vigil√¢ncia otimizada do setor alvo com suporte a m√∫ltiplos formatos.
    """
    log.info("‚ñ∂Ô∏è FASE 2: Iniciando Vigil√¢ncia Otimizada do Setor")
    log.info(f"üéØ Alvo: {TARGET_SECTOR_SLUG.upper()}")

    with httpx.Client(
        cookies=session_cookies, 
        headers=HEADERS, 
        timeout=30.0, 
        follow_redirects=True
    ) as client:
        
        for attempt in range(1, MAX_WATCH_ATTEMPTS + 1):
            log.info(f"üîç --- Vigil√¢ncia #{attempt}/{MAX_WATCH_ATTEMPTS} ---")
            
            try:
                # === VERIFICA√á√ÉO DA SESS√ÉO ===
                client.headers['Referer'] = CATEGORIA_URL
                response = client.get(SETORES_URL)
                
                # Verifica se a sess√£o expirou
                if "/auth/login/" in str(response.url):
                    log.error("‚ùå FALHA CR√çTICA: Sess√£o expirou! Necess√°rio novo login.")
                    return False
                
                # Salva HTML para debug (opcional)
                DEBUG_HTML_FILE.write_text(response.text, encoding='utf-8')
                
                # === AN√ÅLISE DOS SETORES ===
                soup = BeautifulSoup(response.text, "html.parser")
                target_available = analyze_and_log_sectors(soup)
                
                # === ATAQUE SE DISPON√çVEL ===
                if target_available:
                    log.info(f"üö® OPORTUNIDADE DETECTADA! Setor '{TARGET_SECTOR_SLUG.upper()}' dispon√≠vel!")
                    
                    attack_success = attempt_sector_attack(client, soup)
                    
                    if attack_success:
                        return True
                    else:
                        log.error("‚ùå ATAQUE FALHOU! Oportunidade n√£o convertida.")
                        log.warning("üîÑ Continuando vigil√¢ncia...")
                
                else:
                    # Setor n√£o dispon√≠vel - continua vigil√¢ncia
                    next_interval = random.uniform(WATCH_INTERVAL_MIN, WATCH_INTERVAL_MAX)
                    log.info(f"‚è≥ Pr√≥xima verifica√ß√£o em {next_interval:.1f}s...")
                    time.sleep(next_interval)
                    continue

            except httpx.RequestError as req_error:
                log.error(f"üåê Erro de rede: {req_error}")
                log.info("‚è≥ Aguardando 10s antes de tentar novamente...")
                time.sleep(10)
                continue
                
            except Exception as unexpected_error:
                log.exception(f"üí• Erro inesperado na vigil√¢ncia:")
                time.sleep(5)
                continue
        
    log.error(f"‚ùå Esgotadas as {MAX_WATCH_ATTEMPTS} tentativas de vigil√¢ncia.")
    log.info("‚è∞ Limite de tentativas atingido. Encerrando.")
    return False

def main():
    """Fun√ß√£o principal do bot worker."""
    log.info("üöÄ BOT WORKER INICIADO!")
    log.info("=" * 60)
    log.info(f"üéØ Setor alvo: {TARGET_SECTOR_SLUG.upper()}")
    log.info(f"üéÆ Jogo: {JOGO_SLUG}")
    log.info(f"üë• Dependentes: EXTRA√á√ÉO DIN√ÇMICA")
    log.info(f"üîÑ M√°ximo de tentativas: {MAX_WATCH_ATTEMPTS}")
    log.info(f"‚è±Ô∏è Intervalo: {WATCH_INTERVAL_MIN}s - {WATCH_INTERVAL_MAX}s")
    log.info("=" * 60)
    
    attempt_count = 0
    max_login_attempts = 5
    
    while attempt_count < max_login_attempts:
        attempt_count += 1
        log.info(f"üîë Tentativa de autentica√ß√£o #{attempt_count}/{max_login_attempts}")
        
        # Obt√©m sess√£o autenticada
        cookies = get_authenticated_session()
        
        if cookies:
            log.info("‚úÖ Sess√£o autenticada obtida com sucesso!")
            log.info("üîç Iniciando processo de vigil√¢ncia...")
            
            # Executa vigil√¢ncia
            mission_completed = watch_and_attack(cookies)
            
            if mission_completed:
                log.info("üèÅ MISS√ÉO CONCLU√çDA COM SUCESSO! Encerrando worker.")
                break
            else:
                log.warning("‚ö†Ô∏è Vigil√¢ncia finalizada sem sucesso.")
                
                if attempt_count < max_login_attempts:
                    log.info(f"üîÑ Tentando nova autentica√ß√£o em 2 minutos...")
                    time.sleep(120)  # Aguarda 2 minutos antes de tentar novo login
                else:
                    log.error("‚ùå M√°ximo de tentativas de login atingido.")
                    break
        else:
            log.error(f"‚ùå Falha na autentica√ß√£o (tentativa {attempt_count})")
            
            if attempt_count < max_login_attempts:
                wait_time = min(300 * attempt_count, 1800)  # Aumenta o tempo de espera, m√°x 30min
                log.info(f"‚è≥ Aguardando {wait_time//60}min antes da pr√≥xima tentativa...")
                time.sleep(wait_time)
            else:
                log.error("‚ùå M√°ximo de tentativas de autentica√ß√£o atingido.")
                break
    
    log.info("üîö Worker finalizado.")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        log.info("‚ö†Ô∏è Worker interrompido pelo usu√°rio.")
    except Exception as e:
        log.exception(f"üí• Erro fatal no worker: {e}")
    finally:
        log.info("üëã Bot Worker encerrado.")
